=================================
Running the pipeline at GLS South 
=================================


Hardware infrastructure
-----------------------

Currently GLS South has two sequencers and one computer to run the analysis of NGS samples. These are the main actors:

Sequencers
^^^^^^^^^^

The two sequences are:

* NextSeq
* MiSeq

Analysis of MiSeq data takes roughly one hour per sample, while NextSeq takes around 4 hours in total.


Computers
^^^^^^^^^

The computer used for the analysis is::

	10.133.72.112 - RedHat Enterprise


Location of programs/files in each machine
------------------------------------------

The pipeline was installed and tested including all requirements in the new machine at 10.133.72.112.

In order to have a better file organization, most of the binaries, support files (reference, GATK bundle, etc) and main pipeline code were moved in::

	/opt/gls/

with different file types in different subdirectories (please refer to :doc:`running_south` for a full list of the files).

Executables
^^^^^^^^^^^

Executables, compiled or Java jar files, were put in the same sub-directory and are owned by **pipeline** user::


	/opt/gls/bin


Python environment
^^^^^^^^^^^^^^^^^^

In order to avoid conflicts with other Python scripts, all the requirements for the pipeline and dashboard to run are self-contained in a virtual enviroment, located at::

	/opt/gls/pipeline_env

In order to run the pipeline this virtual enviroment needs to be activated with::

	> source /opt/gls/pipeline_env/bin/activate

This should change the Python interpreter and display a change on the bash prompt. To deactivate it, enter on the CLI::

	> deactivate

This python environment is also owned by the **pipeline** user and it has to be started/stopped by this user.


Reference files
^^^^^^^^^^^^^^^

Reference files (named ``hg19.<extension>``) are on::

    /data/GLS_pipeline_references/hg19_ref

All files are now identical to Edmontonâ€™s reference files and lenght discrepancies that caused Picard and GATK errors were fixed.

GATK bundle
^^^^^^^^^^^

GATK bundle was downloaded and stored on::

	/data/GLS_pipeline_references/bundle

Another required file, that list the transcripts for each gene, which is also stored in the same directory. At the moment, this file location is hardcoded in picard_qc.py and it should NOT be moved or modified (*if so and required, the code needs to be modified*). Some newer requirements need to be setup in the same location.

BED and BAIT
^^^^^^^^^^^^

BED and BAIT files are located in::

	/data/GLS_pipeline_references/BED

The BAIT file is almost identical to the BED file and is required by Picard to generate metrics and coverage data.


Pipeline code
^^^^^^^^^^^^^

Pipeline scripts were also moved and put in a subdiretory of ``/opt/gls/pipeline``::
    
    /opt/gls/pipeline 

with the main executing code in::

    /opt/gls/pipeline/code/pipeline/align.py

and configuration files in::

    /opt/gls/pipeline/code/pipeline/config

(this can be modified to any location in the system)


Database
^^^^^^^^

The backend database and its storage location, based on RethinkDB, are owned by **pnuin** and has to be started/stopped with this user, for now. The main configuration for this instance is located at::
	
	/etc/rethinkdb/instance.d

with storage at::

	/var/lib/rethikndb/instance.d 

and at the moment runs on port::

	:5051


Dashboard
^^^^^^^^^

Dashboard code has to be started manually from its location by the **pipeline** user from its location at::

	/opt/gls/pipeline/code/webapps/dashboard

with the code::

	python dashboard.py

The dashboard after being started runs on port::

	:5050 

and can be acceseed by using the IP address of the machine followed by the port number. A better solution is being implemented.


Getting the latest version of the code
--------------------------------------

In order to improve updating the pipeline, the source code was added to a private/protected online repository online.  This allows faster code sharing between both sites, as updates and upgrades can be done by using the command with the **pipeline** user::

	$ git pull origin develop

from inside the::

  /opt/gls/pipeline

directory.

.. toctree::
   :maxdepth: 5


Current status of the automation
--------------------------------

Pipeline has been tested with Illumina provided sample and a NextSeq Calgary-generated sampleset.

Automation has been tested but some minor adjustments have to be added to code.


Manually setting up a pipeline run
----------------------------------

Needs change, but same principles can be followed.

It is pretty simple to setup a run following these instructions:

* Create a directory on in the FASTQ data storage 
* In this new directory create a subdirectory with the name ``BaseCalls`` and transfer all FASTQs into it
* Open a text editor and create a file with the name ``Cplus_2017_NGS_XX`` (replace the XX with your run number or use the lab internal code for run)
* In this file enter these lines::

	BAIT: /opt/gls/BED/Inherited_Cancer_panel_FINAL.picard.bed
	BED:
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	  <sample ID>: <bed file>
	Datadir: <run dir>
	FinalDir: <run name>
	Panel: CancerPlus
	Reference: /opt/gls/reference/hg19.fasta
	VCF: /opt/gls/bundle/dbsnp_138.hg19.vcf


* replace <sample ID> with the MDL number for that sample
* replace <bed file> with the corresponding BED file to be used for that sample, for instance::

       HNPCC - /data/GLS_pipeline_references/BED/Inherited_Cancer_panel_BED_91122_Target_adjusted_FINAL_HNPCC_4genes.bed
       BRCA - /data/GLS_pipeline_references/BED/Inherited_Cancer_panel_BED_91122_Target_adjusted_FINAL_BRCApanel.bed
       BRCA/HNPCC - /data/GLS_pipeline_references/BED/Inherited_Cancer_panel_BED_91122_Target_adjusted_FINAL_both.bed
       Cplus - /data/GLS_pipeline_references/BED/Inherited_Cancer_panel_FINAL.bed
       All - /data/GLS_pipeline_references/BED/Inherited_Cancer_panel_FINAL.bed
       

* open a Terminal if it is not running 
* On the terminal enter these commands::

	> cd
	> tmux
	> source /opt/gls/pipeline_env/bin/activate
	> cd /opt/gls/pipeline/code/pipeline
	> python align.py /<data dir>/<run id>/<YAML file name>

where the run id is the run you want to analyse, i.e. ``161207_M02619_0072_000000000-ATMCN_Cplus_2016_NGS_10``, and the YAML file name for this run is ``Cplus_2016_NGS_10.yaml``

You should see messages coming on the screen and BWA will start the alignment.  If unsuccessful, please email for support.



.. _Bitbucket: https://bitbucket.org/nuin/ngs-pipeline/